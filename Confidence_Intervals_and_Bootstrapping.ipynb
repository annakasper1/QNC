{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkshQMZGgVyXcN1zKOvXOh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annakasper1/QNC/blob/main/Confidence_Intervals_and_Bootstrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: Compute confidence/credible intervals based on the four methods above for simulated data sampled from a population that is Gaussian distributed with mean\n",
        "mu=10 and standard deviation\n",
        "sigma =2, for n=5, 10, 20, 40, 80, 160, 1000 at a 95% confidence level."
      ],
      "metadata": {
        "id": "YPeAs2VL4Oxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 1: Using Z-scores, which assume large n, Gaussian distribution, and/or known standard deviation (sigma).**\n",
        "\n",
        "ChatGPT prompt: create a python script that will calculate the confidence interval using the knowledge that the mean = 10, the confidence level = 95%, and that the standard deviation = 2. The script should calculate the confidence intervals using the following list of sample sizes (n): 2, 5, 10, 20, 40, 80, 160, and 1000. Utilize the z-scores to calculate the confidence intervals, since the standard deviation is known.\n",
        "\n",
        "The CI interval obtained by the code for n = 80 was double-checked manually.\n"
      ],
      "metadata": {
        "id": "OwhFiJY9C6I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Given values\n",
        "mean = 10\n",
        "std_dev = 2\n",
        "confidence_level = 0.95\n",
        "sample_sizes = [2, 5, 10, 20, 40, 80, 160, 1000]\n",
        "\n",
        "# z-critical value for two-tailed 95% confidence interval\n",
        "z_critical = stats.norm.ppf((1 + confidence_level) / 2)\n",
        "\n",
        "# Loop through sample sizes\n",
        "for n in sample_sizes:\n",
        "    # Standard error of the mean\n",
        "    sem = std_dev / math.sqrt(n)\n",
        "    print(f\"n={n:<5} SEM=({sem:.2f}, Z-critical={z_critical:.2f})\") # Print standard error of the mean\n",
        "\n",
        "    margin_of_error = z_critical * sem\n",
        "    print(f\"n={n:<5} Margin of error=({margin_of_error:.2f})\") # Print standard error of the mean\n",
        "\n",
        "    ci_lower = mean - margin_of_error\n",
        "    ci_upper = mean + margin_of_error\n",
        "    print(f\"n={n:<5} CI=({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSgm0l3j4Ztc",
        "outputId": "f741d829-60c4-48db-95b7-7a05cc6cba1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n=2     SEM=(1.41, Z-critical=1.96)\n",
            "n=2     Margin of error=(2.77)\n",
            "n=2     CI=(7.23, 12.77)\n",
            "n=5     SEM=(0.89, Z-critical=1.96)\n",
            "n=5     Margin of error=(1.75)\n",
            "n=5     CI=(8.25, 11.75)\n",
            "n=10    SEM=(0.63, Z-critical=1.96)\n",
            "n=10    Margin of error=(1.24)\n",
            "n=10    CI=(8.76, 11.24)\n",
            "n=20    SEM=(0.45, Z-critical=1.96)\n",
            "n=20    Margin of error=(0.88)\n",
            "n=20    CI=(9.12, 10.88)\n",
            "n=40    SEM=(0.32, Z-critical=1.96)\n",
            "n=40    Margin of error=(0.62)\n",
            "n=40    CI=(9.38, 10.62)\n",
            "n=80    SEM=(0.22, Z-critical=1.96)\n",
            "n=80    Margin of error=(0.44)\n",
            "n=80    CI=(9.56, 10.44)\n",
            "n=160   SEM=(0.16, Z-critical=1.96)\n",
            "n=160   Margin of error=(0.31)\n",
            "n=160   CI=(9.69, 10.31)\n",
            "n=1000  SEM=(0.06, Z-critical=1.96)\n",
            "n=1000  Margin of error=(0.12)\n",
            "n=1000  CI=(9.88, 10.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 2: Using t-table values with Bessel's correction to minimize bias; assuming small n values.**\n",
        "\n",
        "ChatGPT prompt: Create a python script that will calculate the confidence interval using the knowledge that the mean = 10, the confidence level = 95%, and that the standard deviation = 2. The script should calculate the confidence intervals using the following list of sample sizes (n): 2, 5, 10, 20, 40, 80, 160, and 1000. Assume that all sample sizes are considered small and use the t-table.\n",
        "\n",
        "The CI interval obtained by the code for n = 40 was double-checked manually.\n"
      ],
      "metadata": {
        "id": "wbhp_scKGiyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Given values\n",
        "mean = 10\n",
        "std_dev = 2\n",
        "confidence_level = 0.95\n",
        "sample_sizes = [2, 5, 10, 20, 40, 80, 160, 1000]\n",
        "\n",
        "# Loop through sample sizes\n",
        "for n in sample_sizes:\n",
        "    # Standard error of the mean\n",
        "    sem = std_dev / math.sqrt(n)\n",
        "\n",
        "    # Degrees of freedom\n",
        "    df = n - 1\n",
        "\n",
        "    # t-critical value for two-tailed 95% confidence\n",
        "    t_critical = stats.t.ppf((1 + confidence_level) / 2, df)\n",
        "\n",
        "    # Margin of error\n",
        "    margin_of_error = t_critical * sem\n",
        "\n",
        "    # Confidence interval\n",
        "    ci_lower = mean - margin_of_error\n",
        "    ci_upper = mean + margin_of_error\n",
        "\n",
        "    print(f\"n={n:<5} CI=({ci_lower:.3f}, {ci_upper:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgstMwCfHnL9",
        "outputId": "84c9d66b-e148-4a05-f7c1-2b18890465b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n=2     CI=(-7.969, 27.969)\n",
            "n=5     CI=(7.517, 12.483)\n",
            "n=10    CI=(8.569, 11.431)\n",
            "n=20    CI=(9.064, 10.936)\n",
            "n=40    CI=(9.360, 10.640)\n",
            "n=80    CI=(9.555, 10.445)\n",
            "n=160   CI=(9.688, 10.312)\n",
            "n=1000  CI=(9.876, 10.124)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 3: Bootstrapping; no assumptions about the population distribution.**\n",
        "\n",
        "ChatGPT prompt: Switch to the bootstrapping method."
      ],
      "metadata": {
        "id": "JbDM15W2J0bD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Given values\n",
        "true_mean = 10\n",
        "true_std = 2\n",
        "confidence_level = 0.95\n",
        "sample_sizes = [2, 5, 10, 20, 40, 80, 160, 1000]\n",
        "\n",
        "# Number of bootstrap iterations\n",
        "n_bootstrap = 10000\n",
        "\n",
        "# Loop through sample sizes\n",
        "for n in sample_sizes:\n",
        "    # Generate one sample of size n from the normal population\n",
        "    sample = np.random.normal(loc=true_mean, scale=true_std, size=n)\n",
        "\n",
        "    # Bootstrap: resample with replacement and calculate means\n",
        "    boot_means = []\n",
        "    for _ in range(n_bootstrap):\n",
        "        resample = np.random.choice(sample, size=n, replace=True)\n",
        "        boot_means.append(np.mean(resample))\n",
        "\n",
        "    # Compute confidence interval using percentiles\n",
        "    alpha = (1 - confidence_level) / 2\n",
        "    lower = np.percentile(boot_means, 100 * alpha)\n",
        "    upper = np.percentile(boot_means, 100 * (1 - alpha))\n",
        "\n",
        "    print(f\"n={n:<5} CI=({lower:.3f}, {upper:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB21udl9JzoW",
        "outputId": "88c4e5b0-1cf8-44e6-fec3-ddad4e185572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n=2     CI=(11.308, 12.076)\n",
            "n=5     CI=(8.975, 11.398)\n",
            "n=10    CI=(8.357, 10.495)\n",
            "n=20    CI=(8.861, 10.898)\n",
            "n=40    CI=(9.729, 10.980)\n",
            "n=80    CI=(9.430, 10.211)\n",
            "n=160   CI=(9.507, 10.095)\n",
            "n=1000  CI=(10.022, 10.268)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method 4: Bayesian credible intervals; use Bayes' Rule.**\n",
        "\n",
        "ChatGPT prompt: Switch to using Bayes' rule to calculate Bayesian credible intervals."
      ],
      "metadata": {
        "id": "_qxBvRoKKWe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Known values\n",
        "true_mean = 10\n",
        "true_std = 2\n",
        "confidence_level = 0.95\n",
        "sample_sizes = [2, 5, 10, 20, 40, 80, 160, 1000]\n",
        "\n",
        "# Weak prior: Normal(0, 1e6)\n",
        "prior_mean = 0\n",
        "prior_var = 1e6\n",
        "\n",
        "alpha = (1 - confidence_level) / 2\n",
        "\n",
        "for n in sample_sizes:\n",
        "    # Simulate observed data from population\n",
        "    sample = np.random.normal(loc=true_mean, scale=true_std, size=n)\n",
        "    sample_mean = np.mean(sample)\n",
        "\n",
        "    # Posterior variance\n",
        "    post_var = 1 / (1/prior_var + n/(true_std**2))\n",
        "\n",
        "    # Posterior mean\n",
        "    post_mean = post_var * (prior_mean/prior_var + n*sample_mean/(true_std**2))\n",
        "\n",
        "    # Posterior standard deviation\n",
        "    post_std = np.sqrt(post_var)\n",
        "\n",
        "    # Credible interval (percentiles of posterior Normal)\n",
        "    lower = stats.norm.ppf(alpha, loc=post_mean, scale=post_std)\n",
        "    upper = stats.norm.ppf(1-alpha, loc=post_mean, scale=post_std)\n",
        "\n",
        "    print(f\"n={n:<5} Bayesian CI=({lower:.3f}, {upper:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgXFr_s0KVuj",
        "outputId": "8ed13ab7-3258-446d-b47b-6809af4c26c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n=2     Bayesian CI=(6.227, 11.771)\n",
            "n=5     Bayesian CI=(8.151, 11.657)\n",
            "n=10    Bayesian CI=(7.845, 10.324)\n",
            "n=20    Bayesian CI=(9.560, 11.313)\n",
            "n=40    Bayesian CI=(9.695, 10.934)\n",
            "n=80    Bayesian CI=(9.760, 10.636)\n",
            "n=160   Bayesian CI=(9.632, 10.252)\n",
            "n=1000  Bayesian CI=(9.907, 10.155)\n"
          ]
        }
      ]
    }
  ]
}